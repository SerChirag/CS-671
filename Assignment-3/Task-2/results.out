(300, 224, 224, 3) (300, 224, 224, 2)
python 3.5.2 (default, Nov 12 2018, 13:43:14) 
[GCC 5.4.0 20160609]
keras version 2.2.4
tensorflow version 1.13.1
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 224, 224, 3)  0                                            
__________________________________________________________________________________________________
block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    
__________________________________________________________________________________________________
block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               
__________________________________________________________________________________________________
block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               
__________________________________________________________________________________________________
block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                
__________________________________________________________________________________________________
block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               
__________________________________________________________________________________________________
block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               
__________________________________________________________________________________________________
block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                
__________________________________________________________________________________________________
block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               
__________________________________________________________________________________________________
block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               
__________________________________________________________________________________________________
block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               
__________________________________________________________________________________________________
block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                
__________________________________________________________________________________________________
block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               
__________________________________________________________________________________________________
block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               
__________________________________________________________________________________________________
block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               
__________________________________________________________________________________________________
block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                
__________________________________________________________________________________________________
block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               
__________________________________________________________________________________________________
block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               
__________________________________________________________________________________________________
block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               
__________________________________________________________________________________________________
conv6 (Conv2D)                  (None, 7, 7, 4096)   102764544   block5_pool[0][0]                
__________________________________________________________________________________________________
pool4_11 (Conv2D)               (None, 14, 14, 2)    1026        block4_pool[0][0]                
__________________________________________________________________________________________________
conv7 (Conv2D)                  (None, 7, 7, 4096)   16781312    conv6[0][0]                      
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 28, 28, 2)    16          pool4_11[0][0]                   
__________________________________________________________________________________________________
pool3_11 (Conv2D)               (None, 28, 28, 2)    514         block3_pool[0][0]                
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 28, 2)    131072      conv7[0][0]                      
__________________________________________________________________________________________________
add (Add)                       (None, 28, 28, 2)    0           conv2d_transpose_2[0][0]         
                                                                 pool3_11[0][0]                   
                                                                 conv2d_transpose_1[0][0]         
__________________________________________________________________________________________________
conv2d_transpose_3 (Conv2DTrans (None, 224, 224, 2)  256         add[0][0]                        
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 224, 224, 2)  0           conv2d_transpose_3[0][0]         
==================================================================================================
Total params: 134,393,428
Trainable params: 134,393,428
Non-trainable params: 0
__________________________________________________________________________________________________
(255, 224, 224, 3) (255, 224, 224, 2)
(45, 224, 224, 3) (45, 224, 224, 2)
Train on 255 samples, validate on 45 samples
Epoch 1/20
 - 683s - loss: 0.6920 - acc: 0.5200 - val_loss: 0.6808 - val_acc: 0.5424
Epoch 2/20
 - 678s - loss: 0.5911 - acc: 0.6564 - val_loss: 0.3517 - val_acc: 0.8441
Epoch 3/20
 - 677s - loss: 0.2929 - acc: 0.8663 - val_loss: 0.2404 - val_acc: 0.8969
Epoch 4/20
 - 677s - loss: 0.2062 - acc: 0.9144 - val_loss: 0.1673 - val_acc: 0.9319
Epoch 5/20
 - 677s - loss: 0.1626 - acc: 0.9331 - val_loss: 0.1394 - val_acc: 0.9424
Epoch 6/20
 - 680s - loss: 0.1376 - acc: 0.9435 - val_loss: 0.1463 - val_acc: 0.9416
Epoch 7/20
 - 677s - loss: 0.1223 - acc: 0.9497 - val_loss: 0.1229 - val_acc: 0.9490
Epoch 8/20
 - 677s - loss: 0.1113 - acc: 0.9537 - val_loss: 0.1182 - val_acc: 0.9512
Epoch 9/20
 - 677s - loss: 0.1031 - acc: 0.9570 - val_loss: 0.1020 - val_acc: 0.9569
Epoch 10/20
 - 678s - loss: 0.0937 - acc: 0.9604 - val_loss: 0.0947 - val_acc: 0.9602
Epoch 11/20
 - 678s - loss: 0.0867 - acc: 0.9632 - val_loss: 0.0958 - val_acc: 0.9596
Epoch 12/20
 - 677s - loss: 0.0830 - acc: 0.9647 - val_loss: 0.1017 - val_acc: 0.9580
Epoch 13/20
 - 678s - loss: 0.0813 - acc: 0.9654 - val_loss: 0.0879 - val_acc: 0.9619
Epoch 14/20
 - 678s - loss: 0.0767 - acc: 0.9673 - val_loss: 0.0897 - val_acc: 0.9612
Epoch 15/20
 - 677s - loss: 0.0736 - acc: 0.9686 - val_loss: 0.0834 - val_acc: 0.9635
Epoch 16/20
 - 677s - loss: 0.0709 - acc: 0.9696 - val_loss: 0.0814 - val_acc: 0.9646
Epoch 17/20
 - 677s - loss: 0.0690 - acc: 0.9705 - val_loss: 0.0802 - val_acc: 0.9656
Epoch 18/20
 - 678s - loss: 0.0673 - acc: 0.9714 - val_loss: 0.0780 - val_acc: 0.9661
Epoch 19/20
 - 678s - loss: 0.0645 - acc: 0.9726 - val_loss: 0.0758 - val_acc: 0.9674
Epoch 20/20
 - 676s - loss: 0.0611 - acc: 0.9739 - val_loss: 0.0766 - val_acc: 0.9670
(45, 224, 224) (45, 224, 224)
class 00: #TP=1558560, #FP= 26478, #FN=47975, IoU=0.954
class 01: #TP=624907, #FP= 47975, #FN=26478, IoU=0.894
_________________
Mean IoU: 0.924
